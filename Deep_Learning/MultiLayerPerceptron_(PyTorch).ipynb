{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Using_PyTorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOANWlIJJs3uhtJDb9r5xKG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishwarvenugopal/ML-DL_Implementation/blob/master/Deep_Learning/MultiLayerPerceptron_(PyTorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmfLhoUGiXOn",
        "colab_type": "text"
      },
      "source": [
        "# Source: https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELT4EaGigkY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "243c090f-13df-486a-aa83-c6514a798013"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqhgapjalpPe",
        "colab_type": "text"
      },
      "source": [
        "### Data Pre-processing: \n",
        "#### In PyTorch all the preprocessing operations need to be done inside a custom class derived from the Dataset class, so as to fit in the DataLoader function of PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvwHPV0yEez7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBf_mfXvn7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CSVDataset(Dataset):\n",
        "  #loading the dataset\n",
        "  def __init__ (self, path):\n",
        "    df = pd.read_csv(path)\n",
        "    self.X = df.values[:,:-1]\n",
        "    self.y = df.values[:,-1]\n",
        "    self.X = self.X.astype('float32')\n",
        "    self.y = LabelEncoder().fit_transform(self.y)\n",
        "    self.y = self.y.astype('float32')\n",
        "    self.y = self.y.reshape((len(self.y),1))\n",
        "\n",
        "  #get the number of rows in the dataset\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  #get a row at a particular index in the dataset\n",
        "  def __getitem__ (self,idx):\n",
        "    return [self.X[idx],self.y[idx]]\n",
        "  \n",
        "  # get the indices for the train and test rows\n",
        "  def get_splits(self, n_test = 0.33):\n",
        "    test_size = round(n_test * len(self.X))\n",
        "    train_size = len(self.X) - test_size\n",
        "    return random_split(self, [train_size, test_size])  "
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXBU9mO3pqCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Fk5dE-pVP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(path):\n",
        "  dataset = CSVDataset(path)\n",
        "  train, test = dataset.get_splits()\n",
        "  #print(\"Train: {}, Test: {}\".format(train, test))\n",
        "  # Prepare iterable data loader for train and test\n",
        "  train_dl = DataLoader(train, batch_size=32, shuffle = True)\n",
        "  test_dl = DataLoader(test, batch_size = 1024, shuffle = False)\n",
        "  return train_dl, test_dl"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qBBt8411ZGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # For CNNs using images (eg.MNIST), following function can be used to prepar the data\n",
        "\n",
        "# def prepare_data(path):\n",
        "#     # define standardization\n",
        "#     trans = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "#     # load dataset\n",
        "#     train = MNIST(path, train=True, download=True, transform=trans)\n",
        "#     test = MNIST(path, train=False, download=True, transform=trans)\n",
        "#     # prepare data loaders\n",
        "#     train_dl = DataLoader(train, batch_size=64, shuffle=True)\n",
        "#     test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
        "#     return train_dl, test_dl\n",
        "\n",
        "# # This function can then be called as: \n",
        "\n",
        "# from torch.utils.data import DataLoader\n",
        "# from torchvision.datasets import MNIST\n",
        "# from torchvision.transforms import Compose\n",
        "# from torchvision.transforms import ToTensor\n",
        "# from matplotlib.pyplot as plt\n",
        "\n",
        "# path = '~/.torch/datasets/mnist'\n",
        "# train_dl, test_dl = prepare_data(path)\n",
        "# # Plotting from one batch\n",
        "# i, (inputs, targets) = next(enumerate(train_dl))\n",
        "# for i in range(25):\n",
        "# \tplt.subplot(5, 5, i+1)\n",
        "# \tplt.imshow(inputs[i][0], cmap='gray')\n",
        "# plt.show()"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ufnIpWp0mU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3223a84f-a323-41db-bf4d-2243b6b9152b"
      },
      "source": [
        "# Data Preparation for training and testing\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
        "train_dl, test_dl = prepare_data(path)\n",
        "print(\"Train size: {}, Test size: {}\".format(len(train_dl.dataset),len(test_dl.dataset)))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 234, Test size: 116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo0Iex0GErsG",
        "colab_type": "text"
      },
      "source": [
        "### Model Definition:\n",
        "#### A custom class derived from the 'Module' class need to be defined to specify the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58llj__ArFIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Module\n",
        "from torch.nn import Linear,ReLU, Sigmoid\n",
        "from torch.nn.init import kaiming_uniform_\n",
        "from torch.nn.init import xavier_uniform_"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P0zyGUxqChz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a class for a Multi-Layer Perceptron model\n",
        "\n",
        "class MLP(Module):\n",
        "  #Defining the model elements\n",
        "  def __init__(self,n_inputs):\n",
        "    super(MLP,self).__init__()\n",
        "    self.hidden1 = Linear(n_inputs, 10)\n",
        "    kaiming_uniform_(self.hidden1.weight, nonlinearity = 'relu')\n",
        "    self.act1 = ReLU()\n",
        "    self.hidden2 = Linear(10,8)\n",
        "    kaiming_uniform_(self.hidden2.weight, nonlinearity = 'relu')\n",
        "    self.act2 = ReLU()\n",
        "    self.hidden3 = Linear(8,1)\n",
        "    xavier_uniform_(self.hidden3.weight)\n",
        "    self.act3 = Sigmoid()\n",
        "    #For multi-class (eg.3) problems, last layer will be as follows:\n",
        "      # self.hidden3 = Linear(8, 3)\n",
        "      # xavier_uniform_(self.hidden3.weight)\n",
        "      # self.act3 = Softmax(dim=1)\n",
        "\n",
        "  #Defining a forward propagation unit\n",
        "  def forward(self,X):\n",
        "    X = self.hidden1(X)\n",
        "    X = self.act1(X)\n",
        "    X = self.hidden2(X)\n",
        "    X = self.act2(X)\n",
        "    X = self.hidden3(X)\n",
        "    X = self.act3(X)\n",
        "    return X"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdDyMSFBsrRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MLP(34) # Create a model"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrLSIyb0E44q",
        "colab_type": "text"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPHR2Mzxv0MZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import BCELoss\n",
        "from torch.optim import SGD"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDe_OA6xtJym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the model\n",
        "\n",
        "def train_model(train_dl, test_dl):\n",
        "  criterion = BCELoss()\n",
        "  optimizer = SGD(model.parameters(), lr=0.01, momentum = 0.9)\n",
        "  #enumerate epochs\n",
        "  for epoch in range(100):\n",
        "    #enumerate in mini batches\n",
        "    for i, (inputs,targets) in enumerate(train_dl):\n",
        "      optimizer.zero_grad() # Clearing the gradients\n",
        "      yhat = model(inputs)\n",
        "      loss = criterion(yhat,targets)\n",
        "      loss.backward()\n",
        "      optimizer.step() #Update backward weights"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTUsZylwvujC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(train_dl,test_dl)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvQ8k-qhE-0i",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKkVbzZBw9XH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import vstack\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDyB3jHGvy4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the model\n",
        "\n",
        "def evaluate_model(test_dl, model):\n",
        "  predictions, actuals = list(),list()\n",
        "  for i,(inputs,targets) in enumerate(test_dl):\n",
        "    yhat = model(inputs)\n",
        "    #Retrieving predictions and true values as numpy arrays\n",
        "    yhat = yhat.detach().numpy()\n",
        "    actual = targets.numpy()\n",
        "    actual = actual.reshape((len(actual),1))\n",
        "    yhat = yhat.round() #Gives nearest integer class values as predictions\n",
        "    # For multi-class problems, conversion of predictions to class values is as follows:\n",
        "      # yhat = argmax(yhat, axis=1)\n",
        "      # yhat = yhat.reshape((len(yhat), 1))\n",
        "    predictions.append(yhat)\n",
        "    actuals.append(actual)\n",
        "  predictions, actuals = vstack(predictions), vstack(actuals)\n",
        "  #Calculating the accuracy\n",
        "  acc = accuracy_score(actuals, predictions)\n",
        "  return acc"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYMwE3RLw8Az",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b6aeb4b-3502-40bc-9676-0f6439db9245"
      },
      "source": [
        "acc = evaluate_model(test_dl, model)\n",
        "print(\"Accuracy: {}\".format(acc))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8879310344827587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppMkd5jmFDLJ",
        "colab_type": "text"
      },
      "source": [
        "### Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYgu6S8syoF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import Tensor"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGdwi6X2zKBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions\n",
        "\n",
        "def predict(row, model):\n",
        "  row = Tensor([row])\n",
        "  yhat = model(row)\n",
        "  yhat = yhat.detach().numpy()\n",
        "  return yhat"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ReD5V9WxhUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66a5e140-bea8-4870-c262-268e4ed0f02a"
      },
      "source": [
        "# Make a single prediction (Expected class = 1)\n",
        "\n",
        "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
        "yhat = predict(row, model)\n",
        "print(\"Predicted value: {} (i.e Class = {})\".format(yhat,yhat.round()))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted value: [[0.9994531]] (i.e Class = [[1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEOwWZqIyjDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}